{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic regression model\n",
    "\n",
    "#### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load cleaned feature data table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('../data/processed/df_to_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time_on_vent', 'anchor_age', 'spontrr', 'heartrate', 'std_spontrr',\n",
       "       'weight', 'bloodpressure', 'std_pulseox', 'std_heartrate', 'height',\n",
       "       'tidalvolume', 'temp', 'std_bloodpressure', 'pulseox', 're_intub_class',\n",
       "       'gender', 'admission_type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_on_vent</th>\n",
       "      <th>anchor_age</th>\n",
       "      <th>spontrr</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>std_spontrr</th>\n",
       "      <th>weight</th>\n",
       "      <th>bloodpressure</th>\n",
       "      <th>std_pulseox</th>\n",
       "      <th>std_heartrate</th>\n",
       "      <th>height</th>\n",
       "      <th>tidalvolume</th>\n",
       "      <th>temp</th>\n",
       "      <th>std_bloodpressure</th>\n",
       "      <th>pulseox</th>\n",
       "      <th>re_intub_class</th>\n",
       "      <th>gender</th>\n",
       "      <th>admission_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.983333</td>\n",
       "      <td>72.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>3.718759</td>\n",
       "      <td>123.2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.971222</td>\n",
       "      <td>59.921260</td>\n",
       "      <td>387.0</td>\n",
       "      <td>36.444444</td>\n",
       "      <td>20.347548</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>EW EMER.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>3.577709</td>\n",
       "      <td>264.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.788854</td>\n",
       "      <td>13.771952</td>\n",
       "      <td>70.933071</td>\n",
       "      <td>527.0</td>\n",
       "      <td>39.166667</td>\n",
       "      <td>6.350853</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>EW EMER.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>580.233333</td>\n",
       "      <td>81.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.788854</td>\n",
       "      <td>198.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1.673320</td>\n",
       "      <td>4.324350</td>\n",
       "      <td>61.905512</td>\n",
       "      <td>437.0</td>\n",
       "      <td>36.833333</td>\n",
       "      <td>6.418723</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>EW EMER.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170.000000</td>\n",
       "      <td>65.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.316607</td>\n",
       "      <td>205.9</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>3.633180</td>\n",
       "      <td>61.905512</td>\n",
       "      <td>614.0</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>4.505552</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>URGENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83.866667</td>\n",
       "      <td>61.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.455767</td>\n",
       "      <td>199.5</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.694154</td>\n",
       "      <td>66.070866</td>\n",
       "      <td>556.0</td>\n",
       "      <td>36.444444</td>\n",
       "      <td>7.366591</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>EW EMER.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6783</th>\n",
       "      <td>22.216667</td>\n",
       "      <td>74.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.919350</td>\n",
       "      <td>121.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.081666</td>\n",
       "      <td>66.070866</td>\n",
       "      <td>390.0</td>\n",
       "      <td>36.888889</td>\n",
       "      <td>3.271085</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>URGENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6784</th>\n",
       "      <td>143.283333</td>\n",
       "      <td>59.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.035401</td>\n",
       "      <td>233.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.516575</td>\n",
       "      <td>7.582875</td>\n",
       "      <td>66.070866</td>\n",
       "      <td>334.0</td>\n",
       "      <td>36.555556</td>\n",
       "      <td>10.549882</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>EW EMER.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6785</th>\n",
       "      <td>21.216667</td>\n",
       "      <td>57.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>4.163332</td>\n",
       "      <td>255.2</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.032796</td>\n",
       "      <td>2.041241</td>\n",
       "      <td>68.501969</td>\n",
       "      <td>401.0</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>3.405877</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>ELECTIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6786</th>\n",
       "      <td>8.550000</td>\n",
       "      <td>61.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>10.392305</td>\n",
       "      <td>197.1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.983192</td>\n",
       "      <td>2.994439</td>\n",
       "      <td>70.039370</td>\n",
       "      <td>482.0</td>\n",
       "      <td>36.222222</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>EW EMER.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6787</th>\n",
       "      <td>22.600000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.745956</td>\n",
       "      <td>188.8</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.383277</td>\n",
       "      <td>3.731773</td>\n",
       "      <td>66.964567</td>\n",
       "      <td>472.0</td>\n",
       "      <td>37.111111</td>\n",
       "      <td>8.528777</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>EW EMER.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6788 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      time_on_vent  anchor_age  spontrr  heartrate  std_spontrr  weight  \\\n",
       "0        25.983333        72.0     19.0       79.0     3.718759   123.2   \n",
       "1        17.000000        23.0     33.0      122.0     3.577709   264.0   \n",
       "2       580.233333        81.0     24.0       63.0     1.788854   198.0   \n",
       "3       170.000000        65.0     15.0       80.0     2.316607   205.9   \n",
       "4        83.866667        61.0     18.0       73.0     8.455767   199.5   \n",
       "...            ...         ...      ...        ...          ...     ...   \n",
       "6783     22.216667        74.0     15.0       60.0     4.919350   121.0   \n",
       "6784    143.283333        59.0     21.0       88.0     2.035401   233.0   \n",
       "6785     21.216667        57.0     19.0       83.0     4.163332   255.2   \n",
       "6786      8.550000        61.0     19.0       50.0    10.392305   197.1   \n",
       "6787     22.600000        64.0     24.0       74.0     2.745956   188.8   \n",
       "\n",
       "      bloodpressure  std_pulseox  std_heartrate     height  tidalvolume  \\\n",
       "0              62.0     0.000000       1.971222  59.921260        387.0   \n",
       "1             101.0     1.788854      13.771952  70.933071        527.0   \n",
       "2              79.0     1.673320       4.324350  61.905512        437.0   \n",
       "3             105.0     0.577350       3.633180  61.905512        614.0   \n",
       "4              87.0     0.000000       7.694154  66.070866        556.0   \n",
       "...             ...          ...            ...        ...          ...   \n",
       "6783           98.0     0.000000       2.081666  66.070866        390.0   \n",
       "6784           85.0     1.516575       7.582875  66.070866        334.0   \n",
       "6785           78.0     1.032796       2.041241  68.501969        401.0   \n",
       "6786           94.0     0.983192       2.994439  70.039370        482.0   \n",
       "6787           98.0     0.383277       3.731773  66.964567        472.0   \n",
       "\n",
       "           temp  std_bloodpressure  pulseox  re_intub_class gender  \\\n",
       "0     36.444444          20.347548    100.0               0      F   \n",
       "1     39.166667           6.350853     96.0               0      M   \n",
       "2     36.833333           6.418723     96.0               0      F   \n",
       "3     37.333333           4.505552    100.0               0      F   \n",
       "4     36.444444           7.366591    100.0               0      F   \n",
       "...         ...                ...      ...             ...    ...   \n",
       "6783  36.888889           3.271085    100.0               0      F   \n",
       "6784  36.555556          10.549882     96.0               0      M   \n",
       "6785  37.333333           3.405877     96.0               0      F   \n",
       "6786  36.222222           5.656854     97.0               0      M   \n",
       "6787  37.111111           8.528777    100.0               0      M   \n",
       "\n",
       "     admission_type  \n",
       "0          EW EMER.  \n",
       "1          EW EMER.  \n",
       "2          EW EMER.  \n",
       "3            URGENT  \n",
       "4          EW EMER.  \n",
       "...             ...  \n",
       "6783         URGENT  \n",
       "6784       EW EMER.  \n",
       "6785       ELECTIVE  \n",
       "6786       EW EMER.  \n",
       "6787       EW EMER.  \n",
       "\n",
       "[6788 rows x 17 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['re_intub_class']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns.drop('re_intub_class')]\n",
    "y = df['re_intub_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.61      0.73      1355\n",
      "           1       0.13      0.56      0.22       148\n",
      "\n",
      "    accuracy                           0.60      1503\n",
      "   macro avg       0.53      0.58      0.48      1503\n",
      "weighted avg       0.85      0.60      0.68      1503\n",
      "\n",
      "[[822 533]\n",
      " [ 65  83]]\n"
     ]
    }
   ],
   "source": [
    "numeric_features  = df[df.columns.drop(['gender','admission_type','re_intub_class'])].columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "   # ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = df[['gender','admission_type']].columns\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "   # ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('smote', SMOTE(k_neighbors = 5,random_state=101)),\n",
    "                      ('classifier', LogisticRegression())])\n",
    "\n",
    "param_grid = [\n",
    "    {'classifier' : [LogisticRegression()],\n",
    "     'classifier__penalty' : ['l1', 'l2'],\n",
    "    'classifier__C' : np.logspace(-4, 4, 20),\n",
    "    'classifier__solver' : ['liblinear']},\n",
    "    {'classifier' : [RandomForestClassifier()],\n",
    "    'classifier__n_estimators' : list(range(10,101,10)),\n",
    "    'classifier__max_features' : list(range(6,32,5))}\n",
    "]\n",
    "\n",
    "svc_param_grid ={ 'svc__kernel':('linear', 'rbf'), \n",
    "                 'svc__C': [0.1,1, 10, 100, 1000], \n",
    "                 'svc__gamma': [1,0.1,0.01,0.001,0.0001]}\n",
    "\n",
    "gs = GridSearchCV(clf, svc_param_grid, verbose=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state = 101)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "#print(\"model score: %.3f\" % clf.score(X_test, y_test))\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Evaulate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.61      0.73      1355\n",
      "           1       0.13      0.56      0.22       148\n",
      "\n",
      "    accuracy                           0.60      1503\n",
      "   macro avg       0.53      0.58      0.48      1503\n",
      "weighted avg       0.85      0.60      0.68      1503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[822 533]\n",
      " [ 65  83]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(logmodel, \"reintubate_model_log.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(scaler, \"reintubate_scaler.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "### perform train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. SMOTE IT!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from collections import Counter\n",
    "counter = Counter(y_train)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transform the dataset\n",
    "oversample = SMOTE(random_state = 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_smote, y_smote = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "counter = Counter(y_smote)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Do logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logmodel = LogisticRegression(max_iter=1000, C=0.0001)\n",
    "logmodel.fit(X_smote,y_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as a pickle in a file \n",
    "#pickle.dump(logmodel, open(\"reintubate_model_log\", 'wb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_features  = df[df.columns.drop(['gender','admission_type','re_intub_class'])].columns\n",
    "#numeric_transformer = ('scaler', StandardScaler())\n",
    "numeric_transformer = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    remainder='passthrough')\n",
    "\n",
    "\n",
    "categorical_features = df[['gender','admission_type']].columns\n",
    "#categorical_transformer =  ('onehot', OneHotEncoder(drop='first'))\n",
    "categorical_transformer = make_column_transformer(\n",
    "    (OneHotEncoder(drop='first'), categorical_features),\n",
    "    remainder='passthrough')\n",
    "\n",
    "#preprocessor = make_column_transformer(\n",
    " #   transformers=[\n",
    "  #      ('num', numeric_transformer, numeric_features),\n",
    "   #     ('cat', categorical_transformer, categorical_features)],\n",
    "#remainder ='passthrough')\n",
    "\n",
    "clf = Pipeline(steps=[('num', numeric_transformer),\n",
    "                      ('cat', categorical_transformer),\n",
    "                      ('classifier', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Perform feature scaling\n",
    "\n",
    "Because the range of values in the features are not necessarily in the same order of magnitude, we will scale the feature data prior to training the model.\n",
    "\n",
    "* actually... they might not be far off! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mask=['spontRR', 'stdABP', 'meanABP', 'stdSpontRR', 'pulseox', 'stdPulseox',\n",
    "       'temp', 'heartRate', 'stdHeartRate', 'weight', 'height', 'anchor_age',\n",
    "       'time_on_vent']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_traina = X_train.copy()\n",
    "X_testa = X_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train.loc[:,mask])\n",
    "X_traina.loc[:,mask] = scaler.transform(X_train.loc[:,mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#X_train = scaler.transform(X_train)\n",
    "X_testa.loc[:,mask] = scaler.transform(X_test.loc[:,mask])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
