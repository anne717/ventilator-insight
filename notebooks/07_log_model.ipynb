{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic regression model\n",
    "\n",
    "#### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load cleaned feature data table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('../data/processed/df_to_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time_on_vent', 'anchor_age', 'spontrr', 'heartrate', 'std_spontrr',\n",
       "       'weight', 'bloodpressure', 'std_pulseox', 'std_heartrate', 'height',\n",
       "       'tidalvolume', 'temp', 'std_bloodpressure', 'pulseox', 're_intub_class',\n",
       "       'gender', 'admission_type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_on_vent</th>\n",
       "      <th>anchor_age</th>\n",
       "      <th>spontrr</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>std_spontrr</th>\n",
       "      <th>weight</th>\n",
       "      <th>bloodpressure</th>\n",
       "      <th>std_pulseox</th>\n",
       "      <th>std_heartrate</th>\n",
       "      <th>height</th>\n",
       "      <th>tidalvolume</th>\n",
       "      <th>temp</th>\n",
       "      <th>std_bloodpressure</th>\n",
       "      <th>pulseox</th>\n",
       "      <th>re_intub_class</th>\n",
       "      <th>gender</th>\n",
       "      <th>admission_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>659.416667</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>11.631239</td>\n",
       "      <td>167.4</td>\n",
       "      <td>102.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.314369</td>\n",
       "      <td>59.027559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>7.120393</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>URGENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.983333</td>\n",
       "      <td>72.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>3.718759</td>\n",
       "      <td>123.2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.971222</td>\n",
       "      <td>59.921260</td>\n",
       "      <td>387.0</td>\n",
       "      <td>36.444444</td>\n",
       "      <td>20.347548</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>EW EMER.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>3.577709</td>\n",
       "      <td>264.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.788854</td>\n",
       "      <td>13.771952</td>\n",
       "      <td>70.933071</td>\n",
       "      <td>527.0</td>\n",
       "      <td>39.166667</td>\n",
       "      <td>6.350853</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>EW EMER.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>580.233333</td>\n",
       "      <td>81.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.788854</td>\n",
       "      <td>198.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1.673320</td>\n",
       "      <td>4.324350</td>\n",
       "      <td>61.905512</td>\n",
       "      <td>437.0</td>\n",
       "      <td>36.833333</td>\n",
       "      <td>6.418723</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>EW EMER.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170.000000</td>\n",
       "      <td>65.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.316607</td>\n",
       "      <td>205.9</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>3.633180</td>\n",
       "      <td>61.905512</td>\n",
       "      <td>614.0</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>4.505552</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>URGENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8071</th>\n",
       "      <td>49.616667</td>\n",
       "      <td>54.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>5.703313</td>\n",
       "      <td>203.5</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.187735</td>\n",
       "      <td>6.284903</td>\n",
       "      <td>70.039370</td>\n",
       "      <td>529.0</td>\n",
       "      <td>36.555556</td>\n",
       "      <td>16.954842</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>EW EMER.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8072</th>\n",
       "      <td>168.833333</td>\n",
       "      <td>77.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.907411</td>\n",
       "      <td>209.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.097618</td>\n",
       "      <td>64.086614</td>\n",
       "      <td>553.0</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>10.876162</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>ELECTIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8073</th>\n",
       "      <td>21.233333</td>\n",
       "      <td>73.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>7.863796</td>\n",
       "      <td>143.4</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.632456</td>\n",
       "      <td>5.609516</td>\n",
       "      <td>64.980315</td>\n",
       "      <td>431.0</td>\n",
       "      <td>38.277778</td>\n",
       "      <td>11.493081</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>EW EMER.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8074</th>\n",
       "      <td>113.800000</td>\n",
       "      <td>87.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6.345696</td>\n",
       "      <td>193.6</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.516398</td>\n",
       "      <td>2.065591</td>\n",
       "      <td>72.023622</td>\n",
       "      <td>1137.0</td>\n",
       "      <td>36.833333</td>\n",
       "      <td>9.605475</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>EW EMER.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8075</th>\n",
       "      <td>194.566667</td>\n",
       "      <td>56.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>103.0</td>\n",
       "      <td>13.479482</td>\n",
       "      <td>156.9</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.032796</td>\n",
       "      <td>5.115336</td>\n",
       "      <td>59.921260</td>\n",
       "      <td>418.0</td>\n",
       "      <td>36.944444</td>\n",
       "      <td>3.949684</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>EW EMER.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8076 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      time_on_vent  anchor_age  spontrr  heartrate  std_spontrr  weight  \\\n",
       "0       659.416667        70.0      0.0      127.0    11.631239   167.4   \n",
       "1        25.983333        72.0     19.0       79.0     3.718759   123.2   \n",
       "2        17.000000        23.0     33.0      122.0     3.577709   264.0   \n",
       "3       580.233333        81.0     24.0       63.0     1.788854   198.0   \n",
       "4       170.000000        65.0     15.0       80.0     2.316607   205.9   \n",
       "...            ...         ...      ...        ...          ...     ...   \n",
       "8071     49.616667        54.0     14.0       78.0     5.703313   203.5   \n",
       "8072    168.833333        77.0     16.0      100.0     3.907411   209.0   \n",
       "8073     21.233333        73.0      9.0       76.0     7.863796   143.4   \n",
       "8074    113.800000        87.0     17.0       50.0     6.345696   193.6   \n",
       "8075    194.566667        56.0     13.5      103.0    13.479482   156.9   \n",
       "\n",
       "      bloodpressure  std_pulseox  std_heartrate     height  tidalvolume  \\\n",
       "0             102.0     2.000000       7.314369  59.027559          0.0   \n",
       "1              62.0     0.000000       1.971222  59.921260        387.0   \n",
       "2             101.0     1.788854      13.771952  70.933071        527.0   \n",
       "3              79.0     1.673320       4.324350  61.905512        437.0   \n",
       "4             105.0     0.577350       3.633180  61.905512        614.0   \n",
       "...             ...          ...            ...        ...          ...   \n",
       "8071           75.0     1.187735       6.284903  70.039370        529.0   \n",
       "8072           88.0     0.000000       2.097618  64.086614        553.0   \n",
       "8073           67.0     0.632456       5.609516  64.980315        431.0   \n",
       "8074           85.0     0.516398       2.065591  72.023622       1137.0   \n",
       "8075           64.0     1.032796       5.115336  59.921260        418.0   \n",
       "\n",
       "           temp  std_bloodpressure  pulseox  re_intub_class gender  \\\n",
       "0     37.500000           7.120393     94.0               0      F   \n",
       "1     36.444444          20.347548    100.0               0      F   \n",
       "2     39.166667           6.350853     96.0               0      M   \n",
       "3     36.833333           6.418723     96.0               0      F   \n",
       "4     37.333333           4.505552    100.0               0      F   \n",
       "...         ...                ...      ...             ...    ...   \n",
       "8071  36.555556          16.954842     97.0               0      M   \n",
       "8072  37.000000          10.876162    100.0               0      F   \n",
       "8073  38.277778          11.493081     98.0               0      M   \n",
       "8074  36.833333           9.605475     99.0               0      M   \n",
       "8075  36.944444           3.949684     97.0               0      M   \n",
       "\n",
       "     admission_type  \n",
       "0            URGENT  \n",
       "1          EW EMER.  \n",
       "2          EW EMER.  \n",
       "3          EW EMER.  \n",
       "4            URGENT  \n",
       "...             ...  \n",
       "8071       EW EMER.  \n",
       "8072       ELECTIVE  \n",
       "8073       EW EMER.  \n",
       "8074       EW EMER.  \n",
       "8075       EW EMER.  \n",
       "\n",
       "[8076 rows x 17 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['re_intub_class']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns.drop('re_intub_class')]\n",
    "y = df['re_intub_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.86      0.90      1618\n",
      "           1       0.07      0.17      0.09        95\n",
      "\n",
      "    accuracy                           0.82      1713\n",
      "   macro avg       0.51      0.51      0.50      1713\n",
      "weighted avg       0.90      0.82      0.86      1713\n",
      "\n",
      "[[1392  226]\n",
      " [  79   16]]\n"
     ]
    }
   ],
   "source": [
    "numeric_features  = df[df.columns.drop(['gender','admission_type','re_intub_class'])].columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "   # ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = df[['gender','admission_type']].columns\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "   # ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('smote', SMOTE(random_state=101)),\n",
    "                      ('classifier', SVC())])\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "    {'classifier' : [LogisticRegression()],\n",
    "     'classifier__penalty' : ['l1', 'l2'],\n",
    "    'classifier__C' : np.logspace(-4, 4, 20),\n",
    "    'classifier__solver' : ['liblinear']},\n",
    "    {'classifier' : [RandomForestClassifier()],\n",
    "    'classifier__n_estimators' : list(range(10,101,10)),\n",
    "    'classifier__max_features' : list(range(6,32,5))}\n",
    "]\n",
    "\n",
    "svc_param_grid ={ 'svc__kernel':('linear', 'rbf'), \n",
    "                 'svc__C': [0.1,1, 10, 100, 1000], \n",
    "                 'svc__gamma': [1,0.1,0.01,0.001,0.0001]}\n",
    "\n",
    "gs = GridSearchCV(clf, param_grid, verbose=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "#print(\"model score: %.3f\" % clf.score(X_test, y_test))\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Evaulate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.61      0.75      1615\n",
      "           1       0.08      0.52      0.13        98\n",
      "\n",
      "    accuracy                           0.61      1713\n",
      "   macro avg       0.52      0.57      0.44      1713\n",
      "weighted avg       0.90      0.61      0.71      1713\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[992 623]\n",
      " [ 47  51]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(logmodel, \"reintubate_model_log.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(scaler, \"reintubate_scaler.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "### perform train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. SMOTE IT!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from collections import Counter\n",
    "counter = Counter(y_train)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transform the dataset\n",
    "oversample = SMOTE(random_state = 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_smote, y_smote = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "counter = Counter(y_smote)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Do logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logmodel = LogisticRegression(max_iter=1000, C=0.0001)\n",
    "logmodel.fit(X_smote,y_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as a pickle in a file \n",
    "#pickle.dump(logmodel, open(\"reintubate_model_log\", 'wb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_features  = df[df.columns.drop(['gender','admission_type','re_intub_class'])].columns\n",
    "#numeric_transformer = ('scaler', StandardScaler())\n",
    "numeric_transformer = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    remainder='passthrough')\n",
    "\n",
    "\n",
    "categorical_features = df[['gender','admission_type']].columns\n",
    "#categorical_transformer =  ('onehot', OneHotEncoder(drop='first'))\n",
    "categorical_transformer = make_column_transformer(\n",
    "    (OneHotEncoder(drop='first'), categorical_features),\n",
    "    remainder='passthrough')\n",
    "\n",
    "#preprocessor = make_column_transformer(\n",
    " #   transformers=[\n",
    "  #      ('num', numeric_transformer, numeric_features),\n",
    "   #     ('cat', categorical_transformer, categorical_features)],\n",
    "#remainder ='passthrough')\n",
    "\n",
    "clf = Pipeline(steps=[('num', numeric_transformer),\n",
    "                      ('cat', categorical_transformer),\n",
    "                      ('classifier', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Perform feature scaling\n",
    "\n",
    "Because the range of values in the features are not necessarily in the same order of magnitude, we will scale the feature data prior to training the model.\n",
    "\n",
    "* actually... they might not be far off! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mask=['spontRR', 'stdABP', 'meanABP', 'stdSpontRR', 'pulseox', 'stdPulseox',\n",
    "       'temp', 'heartRate', 'stdHeartRate', 'weight', 'height', 'anchor_age',\n",
    "       'time_on_vent']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_traina = X_train.copy()\n",
    "X_testa = X_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train.loc[:,mask])\n",
    "X_traina.loc[:,mask] = scaler.transform(X_train.loc[:,mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#X_train = scaler.transform(X_train)\n",
    "X_testa.loc[:,mask] = scaler.transform(X_test.loc[:,mask])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
