{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic regression model\n",
    "\n",
    "#### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load cleaned feature data table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('../data/processed/df_to_model_labs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time_on_vent', 'anchor_age', 'spontrr', 'heartrate', 'std_spontrr',\n",
       "       'weight', 'sodium', 'abg_po2', 'abg_ph', 'hco3', 'abg_pco2',\n",
       "       'bloodpressure', 'std_pulseox', 'std_heartrate', 'creatinine', 'bun',\n",
       "       'height', 'lactic_acid', 'hemoglobin', 'wbg', 'tidalvolume', 'temp',\n",
       "       'std_bloodpressure', 'pulseox', 're_intub_class', 'gender',\n",
       "       'admission_type', 'tidal_weight'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features  = df[df.columns.drop(['gender','admission_type','re_intub_class'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(continuous_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df['pca-one'] = pca_result[:,0]\n",
    "df['pca-two'] = pca_result[:,1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(\n",
    "    x=\"pca-one\", y=\"pca-two\",\n",
    "    hue=\"re_intub_class\",\n",
    "    palette=sns.color_palette(\"hls\", 2),\n",
    "    data=df,\n",
    "    legend=\"full\",\n",
    "    alpha=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, verbose=1, perplexity=100, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(continuous_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df['tsne-2d-one'] = tsne_results[:,0]\n",
    "df['tsne-2d-two'] = tsne_results[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"re_intub_class\",\n",
    "    palette=sns.color_palette(\"hls\", 2),\n",
    "    data=df,\n",
    "    legend=\"full\",\n",
    "    alpha=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns.drop('re_intub_class')]\n",
    "y = df['re_intub_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features  = df[df.columns.drop(['gender','admission_type','re_intub_class'])].columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "   # ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = df[['gender','admission_type']].columns\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "   # ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(drop = 'first'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(drop='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = scaler.fit_transform(df[numeric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummied =  ohe.fit_transform(df[categorical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = preprocessor.get_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaled_data, y, test_size=0.2,random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE(random_state = 101)\n",
    "X_smote, y_smote = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'penalty' : ['l1', 'l2'],\n",
    "    'C' : np.logspace(-4, 4, 20),\n",
    "    'solver' : ['liblinear']},]\n",
    "\n",
    "rfc_param_grid=[\n",
    "    {'n_estimators' : list(range(10,101,10)),\n",
    "    'max_features' : list(range(6,32,5))}]\n",
    "\n",
    "svc_param_grid ={ 'kernel':('linear', 'rbf'), \n",
    "                 'C': [0.1,1, 10, 100, 1000], \n",
    "                 'gamma': [1,0.1,0.01,0.001,0.0001]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(LogisticRegression(),param_grid,refit=True)\n",
    "clf.fit(X_smote,y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model=sm.Logit(y_smote,X_smote)\n",
    "result=logit_model.fit()\n",
    "print(result.summary(alpha = 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,predictions).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict_log_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = clf.predict(X_train)\n",
    "print(classification_report(y_train,train_predictions))\n",
    "print(confusion_matrix(y_train,train_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = roc_curve(y_test,  y_pred_proba)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Evaulate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(clf, \"reintubate_model_log.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(scaler, \"reintubate_scaler.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "### perform train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. SMOTE IT!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from collections import Counter\n",
    "counter = Counter(y_train)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transform the dataset\n",
    "oversample = SMOTE(random_state = 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_smote, y_smote = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "counter = Counter(y_smote)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Do logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logmodel = LogisticRegression(max_iter=1000, C=0.0001)\n",
    "logmodel.fit(X_smote,y_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as a pickle in a file \n",
    "#pickle.dump(logmodel, open(\"reintubate_model_log\", 'wb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_features  = df[df.columns.drop(['gender','admission_type','re_intub_class'])].columns\n",
    "#numeric_transformer = ('scaler', StandardScaler())\n",
    "numeric_transformer = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    remainder='passthrough')\n",
    "\n",
    "\n",
    "categorical_features = df[['gender','admission_type']].columns\n",
    "#categorical_transformer =  ('onehot', OneHotEncoder(drop='first'))\n",
    "categorical_transformer = make_column_transformer(\n",
    "    (OneHotEncoder(drop='first'), categorical_features),\n",
    "    remainder='passthrough')\n",
    "\n",
    "#preprocessor = make_column_transformer(\n",
    " #   transformers=[\n",
    "  #      ('num', numeric_transformer, numeric_features),\n",
    "   #     ('cat', categorical_transformer, categorical_features)],\n",
    "#remainder ='passthrough')\n",
    "\n",
    "clf = Pipeline(steps=[('num', numeric_transformer),\n",
    "                      ('cat', categorical_transformer),\n",
    "                      ('classifier', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Perform feature scaling\n",
    "\n",
    "Because the range of values in the features are not necessarily in the same order of magnitude, we will scale the feature data prior to training the model.\n",
    "\n",
    "* actually... they might not be far off! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mask=['spontRR', 'stdABP', 'meanABP', 'stdSpontRR', 'pulseox', 'stdPulseox',\n",
    "       'temp', 'heartRate', 'stdHeartRate', 'weight', 'height', 'anchor_age',\n",
    "       'time_on_vent']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_traina = X_train.copy()\n",
    "X_testa = X_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train.loc[:,mask])\n",
    "X_traina.loc[:,mask] = scaler.transform(X_train.loc[:,mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#X_train = scaler.transform(X_train)\n",
    "X_testa.loc[:,mask] = scaler.transform(X_test.loc[:,mask])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
