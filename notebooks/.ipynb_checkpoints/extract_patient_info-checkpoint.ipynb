{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script for function to patient info data\n",
    "\n",
    "This function loads chart events (specified by user-entered ID) into a dataframe, filters events by ventilataed patients and places different chart events into different rows in df/\n",
    "\n",
    "#### import useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import psutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### print virtual memory available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmem = psutil.virtual_memory()\n",
    "print (svmem.available) #in bytes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### print size of database we're pulling from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.getsize('./chartevents.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### figure out chunk size for pandas dataframe reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = pd.read_csv('./chartevents.csv', nrows=10)\n",
    "df_sample_size = df_sample.memory_usage(index=True).sum()\n",
    "my_chunk = (2000000000 / df_sample_size)/10\n",
    "my_chunk = int(my_chunk//1) # we get the integer part\n",
    "print (my_chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) create dataframe structure and set chunksize for iterating data into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_csv = pd.read_csv(\n",
    "    'chartevents.csv',\n",
    "    iterator=True,\n",
    "    chunksize=my_chunk,\n",
    "    dtype={'subject_id': int, 'hadm_id': int, 'stay_id': int, \n",
    "           'charttime' : str, 'storetime': str, 'itemid': int,\n",
    "           'value': str, 'valuenum': float, 'valueuom': str, 'warning': int})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) get chart events data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.concat(\n",
    "    [chunk[(chunk['itemid'] == 220003)|(chunk['itemid'] == 226228)|(chunk['itemid'] == 226545)|\n",
    "           (chunk['itemid'] == 226515)|(chunk['itemid'] == 226724)|(chunk['itemid'] == 227088)|\n",
    "           (chunk['itemid'] == 224639)|(chunk['itemid'] == 226531)|(chunk['itemid'] == 226707)|\n",
    "           (chunk['itemid'] == 226730)]\n",
    "        for chunk in iter_csv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get ids of patients that were ventilated and seletc these patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c73e6135b9c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msvents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample_vents.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hadm_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hadm_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "svents = pd.read_csv('sample_vents.csv')\n",
    "ids = svents['hadm_id']\n",
    "df_result = df_result[df_result['hadm_id'].isin(ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get weight of patients (where duplicate values exist, take average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = df_result[df_result['itemid']==226531]\n",
    "avg_dupValues = weight.groupby('hadm_id')['valuenum'].mean()\n",
    "meanWeight = avg_dupValues.reset_index()\n",
    "meanWeight.columns = (['hadm_id','weight'])\n",
    "meanWeight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get height of patients and convert height in cm to inches (where duplicate values exist, take average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = df_result[(df_result['itemid']==226730)|(df_result['itemid']==226707)]\n",
    "\n",
    "# convert height in cm to inches- divide by 2.74\n",
    "height['valuenum'] = np.where(height['itemid']==226730,(height['valuenum']/2.54),height['valuenum'])\n",
    "avg_dupValues = height.groupby('hadm_id')['valuenum'].mean()\n",
    "meanHeight = avg_dupValues.reset_index()\n",
    "meanHeight.columns = (['hadm_id','height'])\n",
    "meanHeight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load feature table and add height and weight to it\n",
    "\n",
    "make sure feature table only includes correct hadm_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_table = pd.read_csv('feature_table.csv')\n",
    "feature_table = feature_table[feature_table['hadm_id'].isin(ids)]\n",
    "new_df = pd.merge(left = feature_table, right = meanWeight, how = 'left', left_on='hadm_id', right_on='hadm_id')\n",
    "new_df =pd.merge(left = new_df, right = meanHeight, how = 'left', left_on='hadm_id', right_on='hadm_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the admissions data for patient that were ventilated, select features that might be useful in the model or later\n",
    "\n",
    "**** NB, keep getting error messages about setting data values on a slice, this leads to unexpected behavior. i.e. if you run the np.where commands, after re-defining svents_keep, it doesn't establish svents_keep as brand new, the calclations just accumulate from whatever the last value in there was. Also, struggling to rename 'value' column. SHould change this to the df.where df.copy together https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#the-where-method-and-masking\n",
    "\n",
    "1) For 'value' (i.e. length of time patient was on ventilator), convert all readings into hours\n",
    "\n",
    "2) rename 'value' column as 'time)on_vent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svents_keep = svents[['hadm_id', 'endtime', 'value', 'valueuom', 're_intub_class',\n",
    "       'subject_id', 'admittime', 'deathtime', 'admission_type',\n",
    "       'admission_location','marital_status', 'ethnicity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svents_keep['value'] = np.where(svents_keep['valueuom']=='min',(svents_keep['value']/60),svents_keep['value'])\n",
    "svents_keep['value'] = np.where(svents_keep['valueuom']=='day',(svents_keep['value']*24),svents_keep['value'])\n",
    "svents_keep.drop('valueuom',axis=1,inplace=True)\n",
    "svents_keep.rename({\"value\":\"time_on_vent\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add admission table data to feature table and save csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new_df =pd.merge(left = new_df, right = svents_keep, how = 'left', left_on='hadm_id', right_on='hadm_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new_df.to_csv('all_feature_table.csv',index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
