{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic regression model\n",
    "\n",
    "#### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load cleaned feature data table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('../data/processed/df_to_model_heartfail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time_on_vent', 'anchor_age', 'spontrr', 'heartrate', 'std_spontrr',\n",
       "       'weight', 'sodium', 'abg_po2', 'abg_ph', 'hco3', 'abg_pco2',\n",
       "       'bloodpressure', 'std_pulseox', 'std_heartrate', 'creatinine', 'bun',\n",
       "       'lactic_acid', 'hemoglobin', 'wbg', 'tidalvolume', 'std_bloodpressure',\n",
       "       'tidal_weight', 'pulseox', 're_intub_class', 'gender',\n",
       "       'admission_type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['admission_type','time_on_vent'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anchor_age</th>\n",
       "      <th>spontrr</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>std_spontrr</th>\n",
       "      <th>weight</th>\n",
       "      <th>sodium</th>\n",
       "      <th>abg_po2</th>\n",
       "      <th>abg_ph</th>\n",
       "      <th>hco3</th>\n",
       "      <th>abg_pco2</th>\n",
       "      <th>...</th>\n",
       "      <th>bun</th>\n",
       "      <th>lactic_acid</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>wbg</th>\n",
       "      <th>tidalvolume</th>\n",
       "      <th>std_bloodpressure</th>\n",
       "      <th>tidal_weight</th>\n",
       "      <th>pulseox</th>\n",
       "      <th>re_intub_class</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.248495</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>2.262005</td>\n",
       "      <td>5.125154</td>\n",
       "      <td>4.962845</td>\n",
       "      <td>5.214936</td>\n",
       "      <td>2.141242</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>3.637586</td>\n",
       "      <td>...</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>1.131402</td>\n",
       "      <td>2.104134</td>\n",
       "      <td>3.190476</td>\n",
       "      <td>6.317165</td>\n",
       "      <td>2.686546</td>\n",
       "      <td>1.460338</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.248495</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>2.262005</td>\n",
       "      <td>5.125154</td>\n",
       "      <td>4.962845</td>\n",
       "      <td>5.214936</td>\n",
       "      <td>2.141242</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>3.637586</td>\n",
       "      <td>...</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>1.131402</td>\n",
       "      <td>2.104134</td>\n",
       "      <td>3.190476</td>\n",
       "      <td>6.317165</td>\n",
       "      <td>2.686546</td>\n",
       "      <td>1.460338</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.850148</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>4.488636</td>\n",
       "      <td>1.856050</td>\n",
       "      <td>5.571393</td>\n",
       "      <td>4.941642</td>\n",
       "      <td>4.718499</td>\n",
       "      <td>2.136531</td>\n",
       "      <td>3.367296</td>\n",
       "      <td>3.737670</td>\n",
       "      <td>...</td>\n",
       "      <td>3.737670</td>\n",
       "      <td>0.875469</td>\n",
       "      <td>2.388763</td>\n",
       "      <td>2.617396</td>\n",
       "      <td>6.388561</td>\n",
       "      <td>1.331541</td>\n",
       "      <td>1.184456</td>\n",
       "      <td>-0.395725</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.262680</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>4.394449</td>\n",
       "      <td>1.167725</td>\n",
       "      <td>4.872139</td>\n",
       "      <td>4.927254</td>\n",
       "      <td>4.584967</td>\n",
       "      <td>2.145931</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>...</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>0.875469</td>\n",
       "      <td>2.116256</td>\n",
       "      <td>2.595255</td>\n",
       "      <td>6.095825</td>\n",
       "      <td>1.741895</td>\n",
       "      <td>1.485735</td>\n",
       "      <td>-0.395725</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.262680</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>4.394449</td>\n",
       "      <td>1.167725</td>\n",
       "      <td>4.872139</td>\n",
       "      <td>4.927254</td>\n",
       "      <td>4.584967</td>\n",
       "      <td>2.145931</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>...</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>0.875469</td>\n",
       "      <td>2.116256</td>\n",
       "      <td>2.595255</td>\n",
       "      <td>6.095825</td>\n",
       "      <td>1.741895</td>\n",
       "      <td>1.485735</td>\n",
       "      <td>-0.395725</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3696</th>\n",
       "      <td>4.204693</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>4.276666</td>\n",
       "      <td>1.405311</td>\n",
       "      <td>5.619676</td>\n",
       "      <td>5.017280</td>\n",
       "      <td>4.290459</td>\n",
       "      <td>2.124654</td>\n",
       "      <td>3.637586</td>\n",
       "      <td>4.127134</td>\n",
       "      <td>...</td>\n",
       "      <td>4.330733</td>\n",
       "      <td>0.993252</td>\n",
       "      <td>2.341806</td>\n",
       "      <td>2.251292</td>\n",
       "      <td>6.011267</td>\n",
       "      <td>1.933442</td>\n",
       "      <td>0.908693</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3697</th>\n",
       "      <td>4.442651</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>4.804021</td>\n",
       "      <td>2.405094</td>\n",
       "      <td>5.252797</td>\n",
       "      <td>4.941642</td>\n",
       "      <td>4.787492</td>\n",
       "      <td>2.121063</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>3.784190</td>\n",
       "      <td>...</td>\n",
       "      <td>3.688879</td>\n",
       "      <td>0.832909</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>3.310543</td>\n",
       "      <td>5.916202</td>\n",
       "      <td>2.517143</td>\n",
       "      <td>1.080565</td>\n",
       "      <td>-0.709103</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3698</th>\n",
       "      <td>4.356709</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>4.488636</td>\n",
       "      <td>1.905745</td>\n",
       "      <td>5.031744</td>\n",
       "      <td>4.976734</td>\n",
       "      <td>5.379897</td>\n",
       "      <td>2.111425</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>4.204693</td>\n",
       "      <td>...</td>\n",
       "      <td>4.007333</td>\n",
       "      <td>0.741937</td>\n",
       "      <td>2.208274</td>\n",
       "      <td>2.785011</td>\n",
       "      <td>5.880533</td>\n",
       "      <td>2.019496</td>\n",
       "      <td>1.207645</td>\n",
       "      <td>0.373159</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3699</th>\n",
       "      <td>4.143135</td>\n",
       "      <td>3.068053</td>\n",
       "      <td>4.394449</td>\n",
       "      <td>1.777500</td>\n",
       "      <td>5.236442</td>\n",
       "      <td>4.905275</td>\n",
       "      <td>4.812184</td>\n",
       "      <td>2.129421</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>...</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>0.788457</td>\n",
       "      <td>2.208274</td>\n",
       "      <td>2.104134</td>\n",
       "      <td>6.817831</td>\n",
       "      <td>2.185905</td>\n",
       "      <td>1.771957</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3700</th>\n",
       "      <td>4.174387</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>4.317488</td>\n",
       "      <td>1.320677</td>\n",
       "      <td>5.245971</td>\n",
       "      <td>4.927254</td>\n",
       "      <td>5.141664</td>\n",
       "      <td>2.117460</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>3.891820</td>\n",
       "      <td>...</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.741937</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>2.509599</td>\n",
       "      <td>6.159095</td>\n",
       "      <td>2.254316</td>\n",
       "      <td>1.252763</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3701 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      anchor_age   spontrr  heartrate  std_spontrr    weight    sodium  \\\n",
       "0       4.248495  2.995732   4.615121     2.262005  5.125154  4.962845   \n",
       "1       4.248495  2.995732   4.615121     2.262005  5.125154  4.962845   \n",
       "2       3.850148  2.772589   4.488636     1.856050  5.571393  4.941642   \n",
       "3       4.262680  3.218876   4.394449     1.167725  4.872139  4.927254   \n",
       "4       4.262680  3.218876   4.394449     1.167725  4.872139  4.927254   \n",
       "...          ...       ...        ...          ...       ...       ...   \n",
       "3696    4.204693  2.944439   4.276666     1.405311  5.619676  5.017280   \n",
       "3697    4.442651  2.397895   4.804021     2.405094  5.252797  4.941642   \n",
       "3698    4.356709  2.772589   4.488636     1.905745  5.031744  4.976734   \n",
       "3699    4.143135  3.068053   4.394449     1.777500  5.236442  4.905275   \n",
       "3700    4.174387  3.218876   4.317488     1.320677  5.245971  4.927254   \n",
       "\n",
       "       abg_po2    abg_ph      hco3  abg_pco2  ...       bun  lactic_acid  \\\n",
       "0     5.214936  2.141242  3.332205  3.637586  ...  2.772589     1.131402   \n",
       "1     5.214936  2.141242  3.332205  3.637586  ...  2.772589     1.131402   \n",
       "2     4.718499  2.136531  3.367296  3.737670  ...  3.737670     0.875469   \n",
       "3     4.584967  2.145931  3.433987  3.713572  ...  3.091042     0.875469   \n",
       "4     4.584967  2.145931  3.433987  3.713572  ...  3.091042     0.875469   \n",
       "...        ...       ...       ...       ...  ...       ...          ...   \n",
       "3696  4.290459  2.124654  3.637586  4.127134  ...  4.330733     0.993252   \n",
       "3697  4.787492  2.121063  3.044522  3.784190  ...  3.688879     0.832909   \n",
       "3698  5.379897  2.111425  3.401197  4.204693  ...  4.007333     0.741937   \n",
       "3699  4.812184  2.129421  3.258097  3.332205  ...  3.931826     0.788457   \n",
       "3700  5.141664  2.117460  3.218876  3.891820  ...  1.609438     0.741937   \n",
       "\n",
       "      hemoglobin       wbg  tidalvolume  std_bloodpressure  tidal_weight  \\\n",
       "0       2.104134  3.190476     6.317165           2.686546      1.460338   \n",
       "1       2.104134  3.190476     6.317165           2.686546      1.460338   \n",
       "2       2.388763  2.617396     6.388561           1.331541      1.184456   \n",
       "3       2.116256  2.595255     6.095825           1.741895      1.485735   \n",
       "4       2.116256  2.595255     6.095825           1.741895      1.485735   \n",
       "...          ...       ...          ...                ...           ...   \n",
       "3696    2.341806  2.251292     6.011267           1.933442      0.908693   \n",
       "3697    2.302585  3.310543     5.916202           2.517143      1.080565   \n",
       "3698    2.208274  2.785011     5.880533           2.019496      1.207645   \n",
       "3699    2.208274  2.104134     6.817831           2.185905      1.771957   \n",
       "3700    2.484907  2.509599     6.159095           2.254316      1.252763   \n",
       "\n",
       "       pulseox  re_intub_class  gender  \n",
       "0     5.199338               0       F  \n",
       "1     5.199338               0       F  \n",
       "2    -0.395725               0       M  \n",
       "3    -0.395725               0       M  \n",
       "4    -0.395725               0       M  \n",
       "...        ...             ...     ...  \n",
       "3696  5.199338               0       M  \n",
       "3697 -0.709103               0       F  \n",
       "3698  0.373159               0       F  \n",
       "3699  5.199338               0       M  \n",
       "3700  5.199338               0       M  \n",
       "\n",
       "[3701 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns.drop(['re_intub_class'])]\n",
    "y = df['re_intub_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features  = df[df.columns.drop(['gender','re_intub_class'])].columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "   # ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = df[['gender']].columns\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "   # ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(drop = 'first'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "#The order of the columns in the transformed feature matrix follows the order \n",
    "#of how the columns are specified in the transformers list. Columns of the original \n",
    "#feature matrix that are not specified are dropped from the resulting transformed feature matrix,\n",
    "#unless specified in the passthrough keyword. Those columns specified with passthrough \n",
    "#are added at the right to the output of the transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feature_names = preprocessor.transformers[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = X_train.copy()\n",
    "training_data.reset_index(inplace=True)\n",
    "training_data.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.to_feather(\"strip_train_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train = preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "categs= preprocessor.named_transformers_['cat']['onehot']\n",
    "onehot_features = categs.get_feature_names()\n",
    "numeric_feature_names = preprocessor.transformers[0][2]\n",
    "feature_names = np.concatenate((numeric_feature_names.tolist(),onehot_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anchor_age', 'spontrr', 'heartrate', 'std_spontrr', 'weight',\n",
       "       'sodium', 'abg_po2', 'abg_ph', 'hco3', 'abg_pco2', 'bloodpressure',\n",
       "       'std_pulseox', 'std_heartrate', 'creatinine', 'bun', 'lactic_acid',\n",
       "       'hemoglobin', 'wbg', 'tidalvolume', 'std_bloodpressure',\n",
       "       'tidal_weight', 'pulseox', 'x0_M'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_test = preprocessor.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE(random_state = 101)\n",
    "X_smote, y_smote = oversample.fit_resample(scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smote = RandomUnderSampler(random_state = 101, replacement = True)\n",
    "#X_smote, y_smote= smote.fit_resample(scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = {0:90, 1:10}\n",
    "w1 = {0:80, 1:20}\n",
    "w2 = {0:70, 1:30}\n",
    "w3 = {0:60, 1:40}\n",
    "\n",
    "param_grid = [\n",
    "    {'penalty' : ['l1', 'l2'],\n",
    "    'C' : np.logspace(-4, 4, 20),\n",
    "    'solver' : ['liblinear'],\n",
    "    'max_iter' : [1000],\n",
    "    'class_weight': [w,w1,w2,w3]}]\n",
    "\n",
    "rfc_param_grid=[\n",
    "    {'n_estimators' : list(range(10,101,10)),\n",
    "    'max_features' : list(range(4,24,4)),\n",
    "    'class_weight' :[w,w1,w2,w3]}]\n",
    "\n",
    "svc_param_grid ={ 'kernel':('linear', 'rbf'), \n",
    "                 'C': [0.1,1, 10, 100, 1000], \n",
    "                 'gamma': [1,0.1,0.01,0.001,0.0001]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(),\n",
       "             param_grid=[{'class_weight': [{0: 90, 1: 10}, {0: 80, 1: 20},\n",
       "                                           {0: 70, 1: 30}, {0: 60, 1: 40}],\n",
       "                          'max_features': [4, 8, 12, 16, 20],\n",
       "                          'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90,\n",
       "                                           100]}])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(LogisticRegression()),param_grid,refit=True)\n",
    "clf.fit(X_smote,y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.661810\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:         re_intub_class   No. Observations:                 5378\n",
      "Model:                          Logit   Df Residuals:                     5355\n",
      "Method:                           MLE   Df Model:                           22\n",
      "Date:                Mon, 05 Oct 2020   Pseudo R-squ.:                 0.04521\n",
      "Time:                        14:08:22   Log-Likelihood:                -3559.2\n",
      "converged:                       True   LL-Null:                       -3727.7\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.470e-58\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -0.0034      0.032     -0.107      0.915      -0.067       0.060\n",
      "x2            -0.0861      0.031     -2.814      0.005      -0.146      -0.026\n",
      "x3             0.0560      0.032      1.759      0.079      -0.006       0.118\n",
      "x4            -0.0886      0.032     -2.795      0.005      -0.151      -0.026\n",
      "x5            -0.8057      0.275     -2.927      0.003      -1.345      -0.266\n",
      "x6            -0.0230      0.033     -0.701      0.483      -0.087       0.041\n",
      "x7            -0.0075      0.036     -0.212      0.832      -0.077       0.062\n",
      "x8             0.1379      0.046      3.011      0.003       0.048       0.228\n",
      "x9            -0.0519      0.058     -0.896      0.370      -0.166       0.062\n",
      "x10            0.1705      0.056      3.025      0.002       0.060       0.281\n",
      "x11            0.1526      0.035      4.310      0.000       0.083       0.222\n",
      "x12            0.1646      0.036      4.520      0.000       0.093       0.236\n",
      "x13            0.0017      0.034      0.051      0.959      -0.064       0.067\n",
      "x14           -0.0127      0.046     -0.279      0.780      -0.102       0.077\n",
      "x15            0.4212      0.046      9.124      0.000       0.331       0.512\n",
      "x16            0.0803      0.032      2.524      0.012       0.018       0.143\n",
      "x17           -0.0799      0.032     -2.513      0.012      -0.142      -0.018\n",
      "x18            0.1369      0.033      4.208      0.000       0.073       0.201\n",
      "x19            0.6806      0.293      2.324      0.020       0.107       1.255\n",
      "x20            0.0378      0.033      1.134      0.257      -0.028       0.103\n",
      "x21           -0.8488      0.360     -2.357      0.018      -1.555      -0.143\n",
      "x22           -0.1112      0.038     -2.907      0.004      -0.186      -0.036\n",
      "x23           -0.0821      0.041     -2.002      0.045      -0.162      -0.002\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "logit_model=sm.Logit(y_smote,X_smote)\n",
    "result=logit_model.fit()\n",
    "print(result.summary(alpha = 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1    -0.003449\n",
       "x2    -0.086085\n",
       "x3     0.056036\n",
       "x4    -0.088615\n",
       "x5    -0.805651\n",
       "x6    -0.023027\n",
       "x7    -0.007538\n",
       "x8     0.137930\n",
       "x9    -0.051949\n",
       "x10    0.170528\n",
       "x11    0.152577\n",
       "x12    0.164565\n",
       "x13    0.001726\n",
       "x14   -0.012712\n",
       "x15    0.421192\n",
       "x16    0.080283\n",
       "x17   -0.079866\n",
       "x18    0.136912\n",
       "x19    0.680586\n",
       "x20    0.037831\n",
       "x21   -0.848831\n",
       "x22   -0.111177\n",
       "x23   -0.082090\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestClassifier' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-a0842a0589c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "clf.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(scaled_test)\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,predictions).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict_log_proba(scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = clf.predict(scaled_train)\n",
    "print(classification_report(y_train,train_predictions))\n",
    "print(confusion_matrix(y_train,train_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = clf.predict_proba(scaled_test)[::,1]\n",
    "fpr, tpr, _ = roc_curve(y_test,  y_pred_proba)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('heartfail_fpr.txt',fpr)\n",
    "np.savetxt('heartfail_tpr.txt',fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import lime.lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.reset_index(inplace=True)\n",
    "X_test.drop(['index'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_smote,  \n",
    "                              feature_names=feature_names,  \n",
    "                              #class_names=['re_intub_class'], \n",
    "                              #categorical_features=categorical_features ,\n",
    "                              verbose=True, \n",
    "                              mode='classification',\n",
    "                              discretize_continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_test[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf.predict(scaled_test[8,:].reshape(1,-1))\n",
    "explog = explainer.explain_instance(scaled_test[0,:], clf.predict_proba, num_features=5)\n",
    "explog.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = explog.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explog.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = explog.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salient_feature = feature_list[2][0].split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_feats = len(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "for j in np.arange(num_top_feats):\n",
    "    salient_feature = feature_list[j][0].split(' ')\n",
    "    j = j+1\n",
    "    for i in salient_feature:\n",
    "        if i in feature_names:\n",
    "            print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Evaulate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(clf, \"reintubate_model_strip.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(preprocessor, \"reintubate_preprocessor_strip.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "### perform train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. SMOTE IT!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from collections import Counter\n",
    "counter = Counter(y_train)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transform the dataset\n",
    "oversample = SMOTE(random_state = 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_smote, y_smote = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "counter = Counter(y_smote)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Do logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logmodel = LogisticRegression(max_iter=1000, C=0.0001)\n",
    "logmodel.fit(X_smote,y_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as a pickle in a file \n",
    "#pickle.dump(logmodel, open(\"reintubate_model_log\", 'wb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_features  = df[df.columns.drop(['gender','admission_type','re_intub_class'])].columns\n",
    "#numeric_transformer = ('scaler', StandardScaler())\n",
    "numeric_transformer = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    remainder='passthrough')\n",
    "\n",
    "\n",
    "categorical_features = df[['gender','admission_type']].columns\n",
    "#categorical_transformer =  ('onehot', OneHotEncoder(drop='first'))\n",
    "categorical_transformer = make_column_transformer(\n",
    "    (OneHotEncoder(drop='first'), categorical_features),\n",
    "    remainder='passthrough')\n",
    "\n",
    "#preprocessor = make_column_transformer(\n",
    " #   transformers=[\n",
    "  #      ('num', numeric_transformer, numeric_features),\n",
    "   #     ('cat', categorical_transformer, categorical_features)],\n",
    "#remainder ='passthrough')\n",
    "\n",
    "clf = Pipeline(steps=[('num', numeric_transformer),\n",
    "                      ('cat', categorical_transformer),\n",
    "                      ('classifier', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Perform feature scaling\n",
    "\n",
    "Because the range of values in the features are not necessarily in the same order of magnitude, we will scale the feature data prior to training the model.\n",
    "\n",
    "* actually... they might not be far off! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mask=['spontRR', 'stdABP', 'meanABP', 'stdSpontRR', 'pulseox', 'stdPulseox',\n",
    "       'temp', 'heartRate', 'stdHeartRate', 'weight', 'height', 'anchor_age',\n",
    "       'time_on_vent']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_traina = X_train.copy()\n",
    "X_testa = X_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train.loc[:,mask])\n",
    "X_traina.loc[:,mask] = scaler.transform(X_train.loc[:,mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#X_train = scaler.transform(X_train)\n",
    "X_testa.loc[:,mask] = scaler.transform(X_test.loc[:,mask])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
